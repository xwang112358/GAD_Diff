{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_dgl, to_networkx, k_hop_subgraph\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph, to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_khop_subgraph_with_random_walk(pyg_data, node_idx, maxN, p_1hop=0.7):\n",
    "    # Initialize the sampled node set with the central node\n",
    "    sampled_nodes = set([node_idx])\n",
    "    current_node = node_idx\n",
    "    \n",
    "    while len(sampled_nodes) < maxN:\n",
    "        print(f\"Sampled {len(sampled_nodes)} nodes\")\n",
    "        if random.random() < p_1hop:\n",
    "            # Perform a 1-hop random walk (current node is the destination)\n",
    "            neighbors = pyg_data.edge_index[0][pyg_data.edge_index[1] == current_node].tolist()\n",
    "            print(f\"Neighbors: {neighbors}\")\n",
    "            if neighbors:\n",
    "                next_node = random.choice(neighbors)\n",
    "                print(f\"Next node: {next_node}\")\n",
    "                sampled_nodes.add(next_node)\n",
    "                current_node = next_node\n",
    "        else:\n",
    "            # Perform a 2-hop random walk (current node is the destination)\n",
    "            neighbors = pyg_data.edge_index[0][pyg_data.edge_index[1] == current_node].tolist()\n",
    "            if neighbors:\n",
    "                intermediate_node = random.choice(neighbors)\n",
    "                second_neighbors = pyg_data.edge_index[0][pyg_data.edge_index[1] == intermediate_node].tolist()\n",
    "                if second_neighbors:\n",
    "                    next_node = random.choice(second_neighbors)\n",
    "                    sampled_nodes.add(intermediate_node)\n",
    "                    sampled_nodes.add(next_node)\n",
    "                    current_node = next_node\n",
    "        \n",
    "        break\n",
    "\n",
    "        # Stop if we have reached maxN nodes\n",
    "        if len(sampled_nodes) >= maxN:\n",
    "            sampled_nodes = set(list(sampled_nodes)[:maxN])\n",
    "            break\n",
    "    \n",
    "    # Convert sampled nodes to a list\n",
    "    sampled_nodes = list(sampled_nodes)\n",
    "    \n",
    "    # Create a mask for the sampled nodes\n",
    "    node_mask = torch.zeros(pyg_data.num_nodes, dtype=torch.bool)\n",
    "    node_mask[sampled_nodes] = True\n",
    "    \n",
    "    # Filter edges to keep only those that connect sampled nodes\n",
    "    edge_index = pyg_data.edge_index[:, node_mask[pyg_data.edge_index[0]] & node_mask[pyg_data.edge_index[1]]]\n",
    "    \n",
    "    # Remap the node indices in edge_index\n",
    "    node_idx_map = {old_idx: new_idx for new_idx, old_idx in enumerate(sampled_nodes)}\n",
    "    edge_index = torch.tensor(\n",
    "        [[node_idx_map[idx] for idx in edge] for edge in edge_index.t().tolist()],\n",
    "        dtype=torch.long\n",
    "    ).t()\n",
    "    \n",
    "    # Create a new Data object for the subsampled subgraph\n",
    "    subgraph_data = Data(\n",
    "        x=pyg_data.x[sampled_nodes],\n",
    "        edge_index=edge_index,\n",
    "        y=pyg_data.y[sampled_nodes] if pyg_data.y is not None else None,\n",
    "        edge_attr=pyg_data.edge_attr[node_mask[pyg_data.edge_index[0]] & node_mask[pyg_data.edge_index[1]]] if pyg_data.edge_attr is not None else None\n",
    "    )\n",
    "    \n",
    "    return subgraph_data\n",
    "\n",
    "\n",
    "def get_khop_subgraph(pyg_data, node_idx, k, maxN):\n",
    "    subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_idx, k, pyg_data.edge_index, relabel_nodes=True)\n",
    "    hop_dists = torch.full((pyg_data.num_nodes,), -1, dtype=torch.long)\n",
    "    hop_dists[subset] = mapping\n",
    "\n",
    "    if len(subset) > maxN:\n",
    "        # Sort nodes by hop distance in descending order\n",
    "        sorted_nodes = sorted(subset.tolist(), key=lambda n: -hop_dists[n])\n",
    "        subset = torch.tensor(sorted_nodes[:maxN])\n",
    "        edge_index, edge_mask = subgraph(subset, pyg_data.edge_index, relabel_nodes=True, num_nodes=pyg_data.num_nodes)\n",
    "\n",
    "    # Apply NormalizeFeatures and SVDFeatureReduction\n",
    "    subgraph_data = Data(x=pyg_data.x[subset], edge_index=edge_index, num_nodes=len(subset))\n",
    "\n",
    "    label = pyg_data.y[node_idx].item()\n",
    "    subgraph_data.y = torch.tensor([label], dtype=torch.long)\n",
    "    subgraph_data.center_node_idx = mapping[0].item()\n",
    "    return subgraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 530758], train_masks=[11758], val_masks=[11758], test_masks=[11758], num_nodes=11758, y=[11758], x=[11758, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_data = torch.load('./pyg_dataset/tolokers.pt')\n",
    "pyg_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5879 2939 2940\n"
     ]
    }
   ],
   "source": [
    "train_indices = torch.nonzero(pyg_data.train_masks, as_tuple=False).squeeze().tolist()\n",
    "vali_indices = torch.nonzero(pyg_data.val_masks, as_tuple=False).squeeze().tolist()\n",
    "test_indices = torch.nonzero(pyg_data.test_masks, as_tuple=False).squeeze().tolist()\n",
    "\n",
    "print(len(train_indices), len(vali_indices), len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_idx = (pyg_data.y == 1).nonzero().squeeze()\n",
    "train_anomaly_idx = list(set(anomaly_idx.tolist()).intersection(set(train_indices)))\n",
    "len(train_anomaly_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    5,   415,   416,  ..., 11755, 11756, 11757])\n"
     ]
    }
   ],
   "source": [
    "subset, edge_index, mapping, edge_mask = k_hop_subgraph(5, 10, pyg_data.edge_index , relabel_nodes=True, flow='target_to_source')\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10109"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "nx_graph = to_networkx(subgraph, to_undirected=True)\n",
    "components = list(nx.connected_components(nx_graph))\n",
    "if len(components) > 1:\n",
    "    print(f\"Graph contains {len(components)} connected components.\")\n",
    "else:\n",
    "    print(\"Graph is connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Edge Index:\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4, 4, 5],\n",
      "        [1, 0, 2, 1, 3, 2, 4, 3, 5, 4]])\n",
      "\n",
      "Subset nodes (source to target):\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Edge Index (source to target):\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4],\n",
      "        [1, 0, 2, 1, 3, 2, 4, 3]])\n",
      "\n",
      "Subset nodes (target to source):\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Edge Index (target to source):\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4],\n",
      "        [1, 0, 2, 1, 3, 2, 4, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "# Create a sample graph\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 4, 5],\n",
    "                           [2, 2, 4, 4, 6, 6]], dtype=torch.long)\n",
    "\n",
    "# Parameters\n",
    "node_idx = 6  # Node to start the k-hop subgraph extraction\n",
    "num_hops = 2  # Number of hops\n",
    "\n",
    "# Extract k-hop subgraph (source to target)\n",
    "subset_s2t, edge_index_s2t, _, _ = k_hop_subgraph(node_idx, num_hops, edge_index, flow='source_to_target')\n",
    "\n",
    "# Extract k-hop subgraph (target to source)\n",
    "subset_t2s, edge_index_t2s, _, _ = k_hop_subgraph(node_idx, num_hops, edge_index, flow='target_to_source')\n",
    "\n",
    "# Print results\n",
    "print(\"Original Edge Index:\")\n",
    "print(edge_index)\n",
    "\n",
    "print(\"\\nSubset nodes (source to target):\")\n",
    "print(subset_s2t)\n",
    "\n",
    "print(\"Edge Index (source to target):\")\n",
    "print(edge_index_s2t)\n",
    "\n",
    "print(\"\\nSubset nodes (target to source):\")\n",
    "print(subset_t2s)\n",
    "\n",
    "print(\"Edge Index (target to source):\")\n",
    "print(edge_index_t2s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
