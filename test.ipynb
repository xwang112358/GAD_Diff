{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_dgl, to_networkx, k_hop_subgraph, subgraph\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph, to_undirected\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple, Union\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch_geometric.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = torch.load('pyg_dataset/reddit.pt')\n",
    "print(reddit)\n",
    "anomaly_indices = torch.nonzero(reddit.y, as_tuple=False).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_subgraph(pyg_graph, start_node, walk_length, max_nodes, onlyE=False):\n",
    "    edge_index = to_undirected(pyg_graph.edge_index)\n",
    "\n",
    "    # Extract a 2-hop subgraph around the start_node\n",
    "    hop2_subset, hop2_edge_index, mapping, _ = k_hop_subgraph(start_node, num_hops=2, edge_index=edge_index, relabel_nodes=True)\n",
    "    node_mapping = {i: hop2_subset[i].item() for i in range(len(hop2_subset))}\n",
    "    if len(hop2_subset) > max_nodes:\n",
    "        walks = []\n",
    "        while len(set(walks)) < max_nodes:\n",
    "            walk = random_walk(pyg_graph, start_node, walk_length)\n",
    "            walks.extend(walk)\n",
    "            \n",
    "        subset = [item[0] for item in Counter(walks).most_common(max_nodes)]\n",
    "        subg_edge_index, _ = utils.subgraph(subset, edge_index, relabel_nodes=True)\n",
    "        node_mapping = {i: subset[i] for i in range(len(subset))}\n",
    "    else:\n",
    "        subset = hop2_subset\n",
    "        subg_edge_index = hop2_edge_index\n",
    "\n",
    "    x = pyg_graph.y[subset]\n",
    "    x = torch.nn.functional.one_hot(x, num_classes=2).float()\n",
    "    edge_attr = torch.tensor([[0, 1] for _ in range(subg_edge_index.shape[1])])\n",
    "    extra_x = pyg_graph.x[subset]\n",
    "    node_mapping = torch.tensor(list(node_mapping.values()))\n",
    "    y = torch.empty(1, 0)\n",
    "    # remove self-loops or not \n",
    "    if onlyE:\n",
    "        x = torch.ones((len(subset), 1))\n",
    "        \n",
    "    # Create a new data object for the subgraph\n",
    "    d = Data(x=x, edge_index=subg_edge_index, edge_attr = edge_attr, extra_x = extra_x,\n",
    "             num_nodes=len(subset), node_mapping=node_mapping, y = y)\n",
    "    return d\n",
    "\n",
    "def random_walk(pyg_graph, start_node, walk_length=3):\n",
    "    walk = [start_node]\n",
    "    edge_index = pyg_graph.edge_index\n",
    "    for _ in range(walk_length):\n",
    "        neighbors = edge_index[1][edge_index[0] == walk[-1]]\n",
    "        if len(neighbors) == 0:  # If no neighbors, stop the walk\n",
    "            break\n",
    "        next_node = np.random.choice(neighbors.cpu().numpy())\n",
    "        walk.append(next_node)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(random_walk_subgraph(reddit, i, 3, 150, onlyE=True))\n",
    "hop2_subset, hop2_edge_index, mapping, _ = k_hop_subgraph(i, num_hops=2, edge_index=reddit.edge_index, relabel_nodes=True)\n",
    "print(len(hop2_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_subgraphs = []\n",
    "\n",
    "for i in tqdm(range(1500)):\n",
    "    node_idx = random.choice(anomaly_indices)\n",
    "    subgraph = random_walk_subgraph(reddit, node_idx, 3, 150, onlyE=True)\n",
    "    anomaly_subgraphs.append(subgraph)\n",
    "\n",
    "\n",
    "torch.save(anomaly_subgraphs, f'./pyg_dataset/reddit_diffusion/reddit_anomaly.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-aware Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenwang/miniconda3/envs/gad_v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168016], train_masks=[10984, 20], val_masks=[10984, 20], test_masks=[10984, 20], num_nodes=10984, y=[10984], x=[10984, 64])\n"
     ]
    }
   ],
   "source": [
    "from utils import GADDataset\n",
    "data = GADDataset('reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4393) tensor(2196) tensor(4395)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:00<00:00, 748.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subgraph embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/146 [00:00<?, ?it/s]<class 'networkx.utils.decorators.argmap'> compilation 4:4: FutureWarning: normalized_laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "100%|██████████| 146/146 [03:23<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [3073,\n",
       "  9268,\n",
       "  7223,\n",
       "  8777,\n",
       "  2647,\n",
       "  9850,\n",
       "  8843,\n",
       "  9375,\n",
       "  8876,\n",
       "  8901,\n",
       "  3783,\n",
       "  2284,\n",
       "  3314,\n",
       "  9466,\n",
       "  9989,\n",
       "  7954,\n",
       "  9491,\n",
       "  5409,\n",
       "  8486,\n",
       "  8038,\n",
       "  7028,\n",
       "  6517,\n",
       "  2954,\n",
       "  6617,\n",
       "  8667],\n",
       " 7: [6149,\n",
       "  5127,\n",
       "  25,\n",
       "  2591,\n",
       "  3137,\n",
       "  8261,\n",
       "  6219,\n",
       "  4689,\n",
       "  7280,\n",
       "  9845,\n",
       "  3713,\n",
       "  9887,\n",
       "  9888,\n",
       "  9391,\n",
       "  5313,\n",
       "  9926,\n",
       "  3287,\n",
       "  5357,\n",
       "  7407,\n",
       "  8952,\n",
       "  9467,\n",
       "  5381,\n",
       "  9028,\n",
       "  344,\n",
       "  9569,\n",
       "  5475,\n",
       "  7044,\n",
       "  8633,\n",
       "  3530],\n",
       " 4: [4614,\n",
       "  2116,\n",
       "  9322,\n",
       "  644,\n",
       "  8872,\n",
       "  2228,\n",
       "  216,\n",
       "  6400,\n",
       "  3855,\n",
       "  6423,\n",
       "  8983,\n",
       "  1308,\n",
       "  8478,\n",
       "  6430,\n",
       "  4902,\n",
       "  7493,\n",
       "  4956,\n",
       "  2403,\n",
       "  9616,\n",
       "  8599,\n",
       "  428,\n",
       "  9141,\n",
       "  7616,\n",
       "  8651,\n",
       "  9165],\n",
       " 2: [4618,\n",
       "  6167,\n",
       "  7717,\n",
       "  9777,\n",
       "  2113,\n",
       "  3667,\n",
       "  1172,\n",
       "  3228,\n",
       "  6844,\n",
       "  200,\n",
       "  9934,\n",
       "  8930,\n",
       "  248,\n",
       "  8448,\n",
       "  9984,\n",
       "  6919,\n",
       "  1291,\n",
       "  4884,\n",
       "  7466,\n",
       "  3883,\n",
       "  829,\n",
       "  6982,\n",
       "  8559,\n",
       "  6020,\n",
       "  8589,\n",
       "  8110,\n",
       "  9699,\n",
       "  501],\n",
       " 3: [2587,\n",
       "  1595,\n",
       "  7760,\n",
       "  2143,\n",
       "  8320,\n",
       "  4227,\n",
       "  1673,\n",
       "  6309,\n",
       "  7375,\n",
       "  724,\n",
       "  9976,\n",
       "  9479,\n",
       "  6936,\n",
       "  9078,\n",
       "  2447,\n",
       "  8602,\n",
       "  7645,\n",
       "  9183,\n",
       "  9696],\n",
       " 0: [7264, 2149, 1164, 3788, 6863, 8970],\n",
       " 8: [7270, 5311, 3440, 8105],\n",
       " 5: [8416, 3810, 1282, 9541, 8080, 8661, 4057, 1513],\n",
       " 6: [6893],\n",
       " 9: [290]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split(semi_supervised=False, trial_id=1)\n",
    "data.cluster_anomalous_nodes(k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
