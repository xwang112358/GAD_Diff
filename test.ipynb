{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_dgl, to_networkx, k_hop_subgraph, subgraph\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph, to_undirected\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple, Union\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch_geometric.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenwang/miniconda3/envs/gad_v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 530758], train_masks=[11758, 20], val_masks=[11758, 20], test_masks=[11758, 20], num_nodes=11758, y=[11758], x=[11758, 10])\n",
      "Data(edge_index=[2, 530758], train_masks=[11758, 20], val_masks=[11758, 20], test_masks=[11758, 20], num_nodes=11758, y=[11758], x=[11758, 10])\n",
      "torch.Size([11758])\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "from utils import GADDataset\n",
    "\n",
    "data = GADDataset('tolokers')\n",
    "pyg_graph = data.get_pyg_graph(save=False)\n",
    "\n",
    "train_masks = pyg_graph.train_masks\n",
    "train_mask = train_masks[:, 0]\n",
    "print(train_mask.shape)\n",
    "print(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 530758], train_masks=[11758, 20], val_masks=[11758, 20], test_masks=[11758, 20], num_nodes=11758, y=[11758], x=[11758, 10])\n"
     ]
    }
   ],
   "source": [
    "reddit = torch.load('pyg_dataset/tolokers.pt')\n",
    "print(reddit)\n",
    "anomaly_indices = torch.nonzero(reddit.y, as_tuple=False).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_subgraph(pyg_graph, start_node, walk_length, max_nodes, onlyE=False):\n",
    "    edge_index = to_undirected(pyg_graph.edge_index)\n",
    "\n",
    "    # Extract a 2-hop subgraph around the start_node\n",
    "    hop2_subset, hop2_edge_index, mapping, _ = k_hop_subgraph(start_node, num_hops=2, edge_index=edge_index, relabel_nodes=True)\n",
    "    node_mapping = {i: hop2_subset[i].item() for i in range(len(hop2_subset))}\n",
    "    if len(hop2_subset) > max_nodes:\n",
    "        walks = []\n",
    "        while len(set(walks)) < max_nodes:\n",
    "            walk = random_walk(pyg_graph, start_node, walk_length)\n",
    "            walks.extend(walk)\n",
    "            \n",
    "        subset = [item[0] for item in Counter(walks).most_common(max_nodes)]\n",
    "        subg_edge_index, _ = utils.subgraph(subset, edge_index, relabel_nodes=True)\n",
    "        node_mapping = {i: subset[i] for i in range(len(subset))}\n",
    "    else:\n",
    "        subset = hop2_subset\n",
    "        subg_edge_index = hop2_edge_index\n",
    "\n",
    "    x = pyg_graph.y[subset]\n",
    "    x = torch.nn.functional.one_hot(x, num_classes=2).float()\n",
    "    edge_attr = torch.tensor([[0, 1] for _ in range(subg_edge_index.shape[1])])\n",
    "    extra_x = pyg_graph.x[subset]\n",
    "    node_mapping = torch.tensor(list(node_mapping.values()))\n",
    "    y = torch.empty(1, 0)\n",
    "    # remove self-loops or not \n",
    "    if onlyE:\n",
    "        x = torch.ones((len(subset), 1))\n",
    "        \n",
    "    # Create a new data object for the subgraph\n",
    "    d = Data(x=x, edge_index=subg_edge_index, edge_attr = edge_attr, extra_x = extra_x,\n",
    "             num_nodes=len(subset), node_mapping=node_mapping, y = y)\n",
    "    return d\n",
    "\n",
    "def random_walk(pyg_graph, start_node, walk_length=3):\n",
    "    walk = [start_node]\n",
    "    edge_index = pyg_graph.edge_index\n",
    "    for _ in range(walk_length):\n",
    "        neighbors = edge_index[1][edge_index[0] == walk[-1]]\n",
    "        if len(neighbors) == 0:  # If no neighbors, stop the walk\n",
    "            break\n",
    "        next_node = np.random.choice(neighbors.cpu().numpy())\n",
    "        walk.append(next_node)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_undirected, k_hop_subgraph, subgraph\n",
    "from torch_geometric.data import Data\n",
    "from collections import deque\n",
    "\n",
    "def downsample_connected_subgraph(pyg_graph, start_node, max_nodes, onlyE=False):\n",
    "    edge_index = to_undirected(pyg_graph.edge_index)\n",
    "    num_nodes = pyg_graph.num_nodes\n",
    "    \n",
    "    # Start BFS from the start_node\n",
    "    visited = set()\n",
    "    queue = deque([start_node])\n",
    "    visited.add(start_node)\n",
    "    \n",
    "    while queue and len(visited) < max_nodes:\n",
    "        node = queue.popleft()\n",
    "        neighbors = edge_index[1][edge_index[0] == node].cpu().numpy()\n",
    "        np.random.shuffle(neighbors)  # Shuffle to introduce randomness in selection\n",
    "        for neighbor in neighbors:\n",
    "            if len(visited) >= max_nodes:\n",
    "                break\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "    \n",
    "    # Convert the visited set to a list for indexing\n",
    "    subset = list(visited)\n",
    "    subg_edge_index, _ = subgraph(subset, edge_index, relabel_nodes=True)\n",
    "    node_mapping = {i: subset[i] for i in range(len(subset))}\n",
    "\n",
    "    x = pyg_graph.y[subset]\n",
    "    x = torch.nn.functional.one_hot(x, num_classes=2).float()\n",
    "    edge_attr = torch.tensor([[0, 1] for _ in range(subg_edge_index.shape[1])])\n",
    "    extra_x = pyg_graph.x[subset]\n",
    "    node_mapping = torch.tensor(list(node_mapping.values()))\n",
    "    y = torch.empty(1, 0)\n",
    "\n",
    "    if onlyE:\n",
    "        x = torch.ones((len(subset), 1))\n",
    "        \n",
    "    d = Data(x=x, edge_index=subg_edge_index, edge_attr=edge_attr, extra_x=extra_x,\n",
    "             num_nodes=len(subset), node_mapping=node_mapping, y=y, center_node_idx=start_node)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1500 [00:00<01:11, 21.02it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Data.__call__() got an unexpected keyword argument 'relabel_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1500\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     node_idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(anomaly_indices)\n\u001b[0;32m----> 5\u001b[0m     subgraph \u001b[38;5;241m=\u001b[39m \u001b[43mdownsample_connected_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreddit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     anomaly_subgraphs\u001b[38;5;241m.\u001b[39mappend(subgraph)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# torch.save(anomaly_subgraphs, f'./pyg_dataset/reddit_diffusion/reddit_anomaly.pt')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mdownsample_connected_subgraph\u001b[0;34m(pyg_graph, start_node, max_nodes, onlyE)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Convert the visited set to a list for indexing\u001b[39;00m\n\u001b[1;32m     28\u001b[0m subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(visited)\n\u001b[0;32m---> 29\u001b[0m subg_edge_index, _ \u001b[38;5;241m=\u001b[39m \u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelabel_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m node_mapping \u001b[38;5;241m=\u001b[39m {i: subset[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(subset))}\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m pyg_graph\u001b[38;5;241m.\u001b[39my[subset]\n",
      "\u001b[0;31mTypeError\u001b[0m: Data.__call__() got an unexpected keyword argument 'relabel_nodes'"
     ]
    }
   ],
   "source": [
    "anomaly_subgraphs = []\n",
    "\n",
    "for i in tqdm(range(1500)):\n",
    "    node_idx = random.choice(anomaly_indices)\n",
    "    subgraph = downsample_connected_subgraph(reddit, node_idx, 3, 150)\n",
    "    anomaly_subgraphs.append(subgraph)\n",
    "\n",
    "\n",
    "# torch.save(anomaly_subgraphs, f'./pyg_dataset/reddit_diffusion/reddit_anomaly.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-aware Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenwang/miniconda3/envs/gad_v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168016], train_masks=[10984, 20], val_masks=[10984, 20], test_masks=[10984, 20], num_nodes=10984, y=[10984], x=[10984, 64])\n"
     ]
    }
   ],
   "source": [
    "from utils import GADDataset\n",
    "data = GADDataset('reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split(semi_supervised=False, trial_id=1)\n",
    "data.cluster_anomalous_nodes(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hydra': {'job': {'chdir': True}, 'run': {'dir': './'}}, 'general': {'name': 'asn', 'wandb': 'online', 'gpus': 1, 'setting': 'train_scratch', 'resume': None, 'ckpt_path': None, 'sample_every_val': 4, 'check_val_every_n_epochs': 1, 'samples_to_generate': 100, 'samples_to_save': 3, 'chains_to_save': 1, 'log_every_steps': 50, 'number_chain_steps': 8, 'final_model_samples_to_generate': 100, 'final_model_samples_to_save': 30, 'final_model_chains_to_save': 20, 'num_train': -1}, 'model': {'type': 'discrete', 'transition': 'marginal', 'model': 'graph_tf', 'diffusion_steps': 500, 'diffusion_noise_schedule': 'cosine', 'n_layers': 5, 'extra_features': 'all', 'hidden_mlp_dims': {'X': 256, 'E': 128, 'y': 128}, 'hidden_dims': {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}, 'lambda_train': [5, 0]}, 'train': {'n_epochs': 300, 'batch_size': 8, 'accumulate_grad_batches': 1, 'lr': 0.0002, 'clip_grad': None, 'save_model': True, 'num_workers': 0, 'ema_decay': 0, 'weight_decay': '1e-12', 'seed': 0, 'progress_bar': False, 'optimizer': 'adamw'}, 'dataset': {'datadir': 'graph/', 'name': 'bio', 'remove_h': None, 'sample': 'eco'}, 'gad': {'model_config': {'lr': 0.01, 'drop_rate': 0}, 'train_config': {'device': 'cuda', 'epochs': 200, 'patience': 50, 'metric': 'AUPRC', 'inductive': False}, 'trials': 10, 'semi_supervised': 0, 'models': 'GIN', 'datasets': '0', 'inductive': False}, 'augment': {'maxNode': 150, 'start_aug_epoch': 30, 'aug_interval': 50, 'NumSubgraphs': 10, 'diffusion_steps': 20, 'lggm_variant': 'adj'}}\n"
     ]
    }
   ],
   "source": [
    "# get sampled local subgraph\n",
    "import torch\n",
    "from augment import augmentation\n",
    "from torch_geometric.loader import DataLoader \n",
    "import yaml\n",
    "from omegaconf import DictConfig\n",
    "with open('configs/config.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "cfg = DictConfig(cfg)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_subgraph = torch.load('local_subgraphs/reddit_0.pt')\n",
    "subgraph_loader = DataLoader(local_subgraph, batch_size=10, shuffle=True)\n",
    "reddit = torch.load('pyg_dataset/reddit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmenting reddit ...\n",
      "True\n",
      "Marginal distribution of the classes: tensor([1.]) for nodes, tensor([0.9419, 0.0581]) for edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenwang/miniconda3/envs/gad_v2/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp_find_unused_parameters_true')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: `Fabric(strategy='dp'|'ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maugmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreddit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreddit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraph_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gad_diff/GAD_Diff/augment.py:143\u001b[0m, in \u001b[0;36maugmentation\u001b[0;34m(cfg, original_data, dataset_name, subgraph_loader)\u001b[0m\n\u001b[1;32m    140\u001b[0m model \u001b[38;5;241m=\u001b[39m DiscreteDenoisingDiffusion(cfg, input_dims, output_dims, nodes_dist, node_types, edge_types, extra_features, domain_features, subgraph_loader, sampling_metrics, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m    142\u001b[0m use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;66;03m# multiple gpus\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient_clip_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mddp_find_unused_parameters_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Needed to load old checkpoints\u001b[39;49;00m\n\u001b[1;32m    145\u001b[0m \u001b[43m                  \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcheck_val_every_n_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_val_every_n_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                  \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                  \u001b[49m\u001b[43maccumulate_grad_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate_grad_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# get the augmented data (edge_index)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpredict(model, subgraph_loader, ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39maugment\u001b[38;5;241m.\u001b[39mlggm_variant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gad_v2/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:69\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gad_v2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:398\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gad_v2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:173\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gad_v2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:577\u001b[0m, in \u001b[0;36m_AcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_configure_launcher()\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer(strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy_flag\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)` is not compatible with an interactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Fabric(strategy=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddp_notebook\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m creation inside the worker function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, TPUAccelerator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, (SingleTPUStrategy, XLAStrategy)\n\u001b[1;32m    589\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp_find_unused_parameters_true')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: `Fabric(strategy='dp'|'ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "augmentation(cfg, reddit, 'reddit', subgraph_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
